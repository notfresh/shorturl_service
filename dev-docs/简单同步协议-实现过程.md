# Bookmarks 资源组同步实现方案（基础版）

> **前置共识（来自问答）**
> 1. **只做 bookmarks 资源组**：暂不考虑短网址或其他业务；bookmarks 的高内聚实体统一作为一个资源组推/拉。
> 2. **双向同步**：客户端既能拉取服务端增量，也能上传自己的改动（新增/更新/删除）。
> 3. **存储形态**：服务端视每条数据为通用 JSON 资源，不解析业务字段，也不关注实体间关系；客户端自行拆包。
> 4. **约束复用**：沿用基础版假设——秒级时间戳、不考虑并发、级联删除由客户端处理、不引入 change_log/seq。
> 5. **字段与时间**：客户端提交 `resource_id`（UUID 等）、`created_at`、`updated_at`、`deleted_at`；若历史数据缺字段，可用当前时间补齐；服务端直接接受客户端时间。
> 6. **鉴权与隔离**：沿用现有用户体系，所有记录按 `user_id` 隔离，只允许读取/写入当前登录用户的数据。
> 7. **接口规范**：使用 `/api/sync/bookmarks/pull` 与 `/api/sync/bookmarks/push`，无需分页。

---

## 1. 总体思路

- **角色划分**：
  - 服务端只做“同步服务”，负责存储 JSON 资源、根据时间提供增量、接收客户端改动；不承载业务规则。
  - 客户端负责业务语义（schema、级联、冲突 UI）以及本地缓存管理。
- **同步驱动**：使用 `updated_at`（秒级）作为唯一增量条件；客户端保存 `last_sync_time`，下一次同步从该时间之后拉取。
- **数据模型**：用一张通用资源表管理整个 bookmarks 组，字段包括 `user_id`、`resource_id`、`payload`、`created_at`、`updated_at`、`deleted_at`。
- **接口流程**：客户端同步时先调用 pull 拉增量，再调用 push 上传本地改动；不处理并发冲突，默认后写覆盖。

---

## 2. 数据层设计

### 2.1 新建 bookmarks 资源表（示例）

```sql
CREATE TABLE bookmark_resources (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    resource_id VARCHAR(64) NOT NULL,
    payload JSON NOT NULL,
    created_at TIMESTAMP NOT NULL,
    updated_at TIMESTAMP NOT NULL,
    deleted_at TIMESTAMP NULL,
    UNIQUE(user_id, resource_id),
    INDEX(user_id, updated_at),
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

- `resource_id`：客户端自定义的稳定 ID（建议 UUID）；服务端只负责唯一性校验。
- `payload`：完整的 bookmark 聚合体（书签字段、tag 列表等）序列化为 JSON。
- `created_at / updated_at / deleted_at`：直接采用客户端上传的值；如果是服务端首创记录，可填当前时间并同步返回给客户端。
- `deleted_at`：为空表示有效，非空表示软删；服务端永不物理删除。

> 若已有通用资源表，可在其上增加 `resource_type='bookmark'` 过滤；本文以独立表描述，实际实现可复用基础设施。

### 2.2 迁移与初始化

1. 创建 Alembic 迁移脚本，建表并加索引。
2. 若需导入历史数据：
   - 由业务侧生成 JSON payload 与 resource_id；
   - 填充 `created_at`、`updated_at`（没有则使用生成时间），`deleted_at = NULL`。
3. 在模型层加入 SQLAlchemy 映射（例如 `BookmarkResource`）。

---

## 3. 接口设计

### 3.1 GET /api/sync/bookmarks/pull

**请求参数**：
- `last_sync_time`（query）：字符串形式时间戳；第一次同步可传 `0` 或留空。

**流程**：
1. 校验登录状态，得到 `current_user.id`。
2. 将 `last_sync_time` 解析为 `datetime`; 若为空则视为最小时间。
3. 查询 `bookmark_resources`：`user_id = current_user.id AND updated_at > last_sync_time`。
4. 按 `updated_at ASC` 返回全部满足条件的记录（本轮无需分页）。
5. `latest_sync_time` 取本次结果中最大的 `updated_at`；若没有记录，则回传原 `last_sync_time`。

**响应结构**：
```json
{
  "changes": [
    {
      "resource_id": "uuid-1",
      "op": "upsert",
      "payload": { ... },
      "created_at": "2026-02-05T10:00:00Z",
      "updated_at": "2026-02-05T10:20:00Z",
      "deleted_at": null
    },
    {
      "resource_id": "uuid-2",
      "op": "delete",
      "payload": null,
      "created_at": "2026-02-01T09:00:00Z",
      "updated_at": "2026-02-05T10:25:00Z",
      "deleted_at": "2026-02-05T10:25:00Z"
    }
  ],
  "latest_sync_time": "2026-02-05T10:25:00Z"
}
```

- `op` 可由服务端推断：若 `deleted_at` 非空则为 `delete`，否则为 `upsert`。
- `payload` 在删除场景可返回 `null`，由客户端自行执行级联删除。

### 3.2 POST /api/sync/bookmarks/push

**请求体**：
```json
{
  "changes": [
    {
      "resource_id": "uuid-1",
      "op": "upsert",
      "payload": { ... },
      "created_at": "2026-02-05T10:00:00Z",
      "updated_at": "2026-02-05T10:20:00Z",
      "deleted_at": null
    },
    {
      "resource_id": "uuid-2",
      "op": "delete",
      "payload": null,
      "created_at": "2026-02-01T08:00:00Z",
      "updated_at": "2026-02-05T10:25:00Z",
      "deleted_at": "2026-02-05T10:25:00Z"
    }
  ]
}
```

**处理步骤**：
1. 鉴权，得到 `user_id`。
2. 对每条 `change`：
   - 查找 `BookmarkResource.query.filter_by(user_id=user_id, resource_id=resource_id)`。
   - 若不存在：创建新记录，写入 `payload` 和所有时间字段。
   - 若存在：
     - `op == upsert`：更新 `payload`、`created_at`（仅首次为空时补写）、`updated_at`、`deleted_at=NULL`。
     - `op == delete`：仅更新 `deleted_at` 与 `updated_at`，保留原 `payload` 供审计；也可允许客户端传空 `payload`。
3. 全部处理完一次性 `db.session.commit()`。
4. 返回结果：
```json
{
  "applied": ["uuid-1", "uuid-2"],
  "failed": [
    {"resource_id": "uuid-9", "reason": "validation_error"}
  ]
}
```

> 没有幂等控制，若客户端重试会重复执行最后一次写入；在“最后写入覆盖”策略下可接受。

---

## 4. Flask 集成步骤

1. **模型定义**：
   - 在 `app/models.py` 或新模块中定义 `BookmarkResource`（映射上述表结构）。
2. **蓝图**：
   - 新建 `app/sync_bookmarks.py`，创建 `Blueprint('bookmarks_sync', __name__)`。
   - 实现两个路由：`@bp.route('/bookmarks/pull', methods=['GET'])` 与 `@bp.route('/bookmarks/push', methods=['POST'])`。
3. **注册**：
   - 在 `create_app` 中 `from . import sync_bookmarks`，并 `app.register_blueprint(sync_bookmarks.bp, url_prefix='/api/sync')`。
4. **鉴权复用**：
   - 路由用 `@login_required`（与现有站点一致）。
   - 读取 `current_user.id` 作为查询条件。
5. **序列化/反序列化**：
   - 使用 `request.get_json()` 获取 `changes`。
   - 返回响应时 `jsonify` 结构化输出。
6. **错误处理**：
   - 参数缺失、JSON 解析失败等情况返回 400。
   - 数据库异常统一回滚并返回 500。

---

## 5. 客户端同步流程

1. **状态维护**：
   - `last_sync_time`：最新一次成功 pull 后服务端返回的时间。
   - `pending_changes`：待上传的本地改动队列。
2. **首次同步处理（服务端无数据）**：
  - 调用 `GET /api/sync/bookmarks/pull` 后若 `changes` 为空且 `latest_sync_time` 未变化（或为空），
    视为“服务端没有任何数据”。
  - 客户端应进入“全量 push”路径：把本地所有书签作为 `changes` 上传到 `/api/sync/bookmarks/push`。
  - 服务端无需特殊分支处理，按正常 `push` 写入即可。
3. **拉取阶段**：
   - `GET /api/sync/bookmarks/pull?last_sync_time=...`。
   - 对每条记录：若 `deleted_at` 为空则落地/更新，非空则执行本地级联删除。
   - 更新 `last_sync_time = latest_sync_time`。
4. **推送阶段**：
   - 如果有 `pending_changes`，打包成 `changes` 调用 `POST /api/sync/bookmarks/push`。
   - 成功的 `resource_id` 从队列移除；失败的根据 `reason` 做提示或留待下次。
5. **顺序建议**：始终“先 pull 后 push”，以便在上传前先吸收服务端的新状态，减少潜在冲突。

---

## 6. 升级路径（留待未来）

- **性能/可靠性**：当数据量或并发增大，可引入 `change_log + seq`，或为 push 增加 `request_id` 幂等表。
- **权限扩展**：若未来需要共享书签，可在表中增加 `owner_type/owner_id`，并调整查询过滤逻辑。
- **分页**：当单次拉取数据过大时，可为 pull 接口增加 `limit`，并以 `updated_at` + `resource_id` 组合游标续拉。
- **冲突处理**：
  - 在 push 时增加与服务端版本对比，检测 `updated_at` 是否落后。
  - 将冲突记录放入 `failed`，交由客户端 UI 处理。

---

## 7. 结论

该实现方案遵循《同步协议设计过程》中“基础设计”层的原则，但专注于 bookmarks 资源组：
- 服务端保持最简职责（存储 JSON、按时间提供增量、接受客户端时间戳）。
- 客户端掌控业务语义、关系拆解与冲突体验。
- 依托现有 Flask 应用与用户体系，快速嫁接 `/api/sync/bookmarks/pull|push`。

这为后续扩展到更多资源组或更高级的同步机制奠定了清晰、可演进的起点。